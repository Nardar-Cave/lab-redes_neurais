{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYKf7nUfr3Ds"
      },
      "source": [
        "# Redes Neurais Recorrentes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXCEmd7bsDMB"
      },
      "source": [
        "### Descriçao\n",
        "\n",
        "---\n",
        "1. O objetivo deste notebook é construir uma Rede Neural Auto Enconders.\n",
        "2. Utilizaremos o conjunto de dados direto do github, a qual iremos baixar e usar.\n",
        "\n",
        "3. O problema consiste em prever agrupar e criar sistemas de recomendações a partir de avaliações de filmes\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViUNAXbEsEOL"
      },
      "source": [
        "### Dicionário\n",
        "\n",
        "\n",
        "Fields\t                                                  | Type  \t  |    Description                              |\n",
        "----------------------------------------------------------|:---------:|:-------------------------------------------:|\n",
        "Date \t  \t\t\t\t\t\t\t\t\t\t  \t  |string     | Data da alteração |\n",
        "Open\t\t\t\t\t\t\t\t\t\t\t\t\t\t  |float    | preço da abertura                        |\n",
        "High\t\t     \t\t\t\t\t\t\t\t\t\t  |float     | preço mais alto no dia\t               |\n",
        "Low | float | preco mais baixo no dia\n",
        "Close | float | preco de fechamento\n",
        "Volume | float | Volume total do dia\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWNKyN2utYRp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbGrHxYcsJK3"
      },
      "source": [
        "# Instalação dos pacotes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4sIIas-sDif"
      },
      "outputs": [],
      "source": [
        "!pip install pandas numpy scikit-learn keras torch torchvision torchaudio\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oALLv4OsLtG"
      },
      "source": [
        "# Documentação\n",
        "\n",
        "1. **Pandas** -> [Link](https://pandas.pydata.org/docs/)\n",
        "2. **Numpy** -> [Link](https://numpy.org/doc/)\n",
        "3. **Scikit Learn** -> [Link](https://scikit-learn.org/stable/)\n",
        "4. **Keras** -> [Link](https://keras.io/api/)\n",
        "5. **TensorFlow** -> [Link](https://www.tensorflow.org/api_docs/python/tf/keras)\n",
        "6. **PyTorch** -> [Link](https://pytorch.org/docs/stable/index.html)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO-2UwZhXIfq"
      },
      "source": [
        "# Obtendo o dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35jUnruXXKyx"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/batestin1/coding_the_future_dio_redes_neurais.git #clona o repositorio\n",
        "!mv coding_the_future_dio_redes_neurais/dataset /content/ #move apenas a pasta dataset para fora do diretorio\n",
        "!rm -rf coding_the_future_dio_redes_neurais #exclui o restante que nao nos interessa\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xzqHGdzsPsR"
      },
      "source": [
        "# Instalando as bibliotecas\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KXnKQabsQU_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable\n",
        "from keras.models import load_model #para salvar modelos do keras\n",
        "#from tensorflow.keras.models import load_model #para salvar modelos do keras\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8XignQYXrjb"
      },
      "source": [
        "# Lendo os Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G62zr7-eXuaZ"
      },
      "outputs": [],
      "source": [
        "#Importando os dados\n",
        "movies = pd.read_csv('/content/dataset/ae/movies.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
        "users = pd.read_csv('/content/dataset/ae/users.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
        "ratings = pd.read_csv('/content/dataset/ae/ratings.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wz2IwYcxYGIw"
      },
      "outputs": [],
      "source": [
        "movies.head(3) #visualizando apenas tres linhas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SI3XIk_zYIOq"
      },
      "outputs": [],
      "source": [
        "users.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rx0saFCIYJ7U"
      },
      "outputs": [],
      "source": [
        "ratings.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGRdTx-PYOxE"
      },
      "source": [
        "# Preparando os dados de treino e os dados de teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-e688oxuYLXk"
      },
      "outputs": [],
      "source": [
        "training_set = pd.read_csv('/content/dataset/ae/train.csv')\n",
        "training_set = np.array(training_set, dtype = 'int')\n",
        "test_set = pd.read_csv('/content/dataset/ae/test.csv')\n",
        "test_set = np.array(test_set, dtype = 'int')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFk5fYa7YTIg"
      },
      "outputs": [],
      "source": [
        "#Quantidade de usuários e filmes\n",
        "nb_users = int(max(max(training_set[:,0]), max(test_set[:,0])))\n",
        "nb_movies = int(max(max(training_set[:,1]), max(test_set[:,1])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8y8b8fOYo4J"
      },
      "outputs": [],
      "source": [
        "#Convertendo os dados em uma matriz com usuários nas linhas e filmes nas colunas\n",
        "def convert(data):\n",
        "    new_data = []\n",
        "    for id_users in range(1, nb_users + 1):\n",
        "        id_movies = data[:,1][data[:,0] == id_users]\n",
        "        id_ratings = data[:,2][data[:,0] == id_users]\n",
        "        ratings = np.zeros(nb_movies)\n",
        "        ratings[id_movies - 1] = id_ratings\n",
        "        new_data.append(list(ratings))\n",
        "    return new_data\n",
        "training_set = convert(training_set)\n",
        "test_set = convert(test_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OeQidhuYrwS"
      },
      "source": [
        "# Criando Tensors do Torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jH5mXUXsYu2d"
      },
      "outputs": [],
      "source": [
        "training_set = torch.FloatTensor(training_set)\n",
        "test_set = torch.FloatTensor(test_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwUaOi69Yyvr"
      },
      "source": [
        "# Criando a arquitetura da AE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5DxFIeMY0td"
      },
      "outputs": [],
      "source": [
        "class SAE(nn.Module):\n",
        "    def __init__(self, ):\n",
        "        super(SAE, self).__init__()\n",
        "        self.fc1 = nn.Linear(nb_movies, 20)\n",
        "        self.fc2 = nn.Linear(20, 10)\n",
        "        self.fc3 = nn.Linear(10, 20)\n",
        "        self.fc4 = nn.Linear(20, nb_movies)\n",
        "        self.activation = nn.Sigmoid()\n",
        "    def forward(self, x):\n",
        "        x = self.activation(self.fc1(x))\n",
        "        x = self.activation(self.fc2(x))\n",
        "        x = self.activation(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "sae = SAE()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.RMSprop(sae.parameters(), lr = 0.01, weight_decay = 0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQqfmK6Y4UL"
      },
      "source": [
        "# Treinando a AE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Clt7r9foY7y1"
      },
      "outputs": [],
      "source": [
        "nb_epoch = 200\n",
        "for epoch in range(1, nb_epoch + 1):\n",
        "    train_loss = 0\n",
        "    s = 0.\n",
        "    for id_user in range(nb_users):\n",
        "        input = Variable(training_set[id_user]).unsqueeze(0)\n",
        "        target = input.clone()\n",
        "        if torch.sum(target.data > 0) > 0:\n",
        "            output = sae(input)\n",
        "            target.require_grad = False\n",
        "            output[target == 0] = 0\n",
        "            loss = criterion(output, target)\n",
        "            mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
        "            loss.backward()\n",
        "            train_loss += np.sqrt(loss.data*mean_corrector)\n",
        "            s += 1.\n",
        "            optimizer.step()\n",
        "    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SspaKiyXY_T1"
      },
      "source": [
        "# Testando a Rede"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6x3t-T3hZFPC"
      },
      "outputs": [],
      "source": [
        "test_loss = 0\n",
        "s = 0.\n",
        "for id_user in range(nb_users):\n",
        "    input = Variable(training_set[id_user]).unsqueeze(0)\n",
        "    target = Variable(test_set[id_user]).unsqueeze(0)\n",
        "    if torch.sum(target.data > 0) > 0:\n",
        "        output = sae(input)\n",
        "        target.require_grad = False\n",
        "        output[target == 0] = 0\n",
        "        loss = criterion(output, target)\n",
        "        mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
        "        test_loss += np.sqrt(loss.data*mean_corrector)\n",
        "        s += 1.\n",
        "print('Loss de test:: '+str(test_loss/s))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBZ0WfOuZGSM"
      },
      "source": [
        "# Salvando o modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCWcMAD6ZOTV"
      },
      "outputs": [],
      "source": [
        "folder = 'ae/'\n",
        "\n",
        "# Verifica se o diretório existe e, se não existir, cria o diretório\n",
        "if not os.path.exists(folder):\n",
        "    os.makedirs(folder)\n",
        "\n",
        "\n",
        "# Salva o modelo no diretório especificado\n",
        "torch.save(sae.state_dict(), os.path.join(folder, 'redes_auto_enconder.h5'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4U0kkRcazAi"
      },
      "source": [
        "# Importando os modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49s5dkEhazvK"
      },
      "outputs": [],
      "source": [
        "#model = load_model(os.path.join(folder, 'redes_auto_enconder.h5'))\n",
        "\n",
        "model = sae.load_state_dict(torch.load(os.path.join(folder, 'redes_auto_enconder.h5')))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dNacZBsa70H"
      },
      "outputs": [],
      "source": [
        "model"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
