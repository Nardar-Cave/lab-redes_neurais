{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Redes Neurais Auto Encoders"
      ],
      "metadata": {
        "id": "fYKf7nUfr3Ds"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Descriçao\n",
        "\n",
        "---\n",
        "1. O objetivo deste notebook é construir uma Rede Neural Auto Enconders.\n",
        "2. Utilizaremos o conjunto de dados direto do github, a qual iremos baixar e usar.\n",
        "\n",
        "3. O problema consiste em prever agrupar e criar sistemas de recomendações a partir de avaliações de filmes\n",
        "---"
      ],
      "metadata": {
        "id": "VXCEmd7bsDMB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dicionário do arquivo movies\n",
        "\n",
        "\n",
        "Fields\t                                                  | Type  \t  |    Description                              |\n",
        "----------------------------------------------------------|:---------:|:-------------------------------------------:|\n",
        "indice_filme \t  \t\t\t\t\t\t\t\t\t\t  \t  |string     | Indice do filme |\n",
        "nome_filme\t\t\t\t\t\t\t\t\t\t\t\t\t\t  |string    | Título do Filme                        |\n",
        "genero_filme\t\t     \t\t\t\t\t\t\t\t\t\t  |string     | Genero do filme               |\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "ViUNAXbEsEOL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dicionário do arquivo user\n",
        "\n",
        "Fields\t                                                  | Type  \t  |    Description                              |\n",
        "----------------------------------------------------------|:---------:|:-------------------------------------------:|\n",
        "indice_user \t  \t\t\t\t\t\t\t\t\t\t  \t  |string     | Indice do usuário |\n",
        "genero_user\t\t\t\t\t\t\t\t\t\t\t\t\t\t  |string    | Genero do usuário                      |\n",
        "idade_user\t\t     \t\t\t\t\t\t\t\t\t\t  |int     | Idade do usuário               |\n",
        "cod_profissao\t\t     \t\t\t\t\t\t\t\t\t\t  |int     | código da profissão               |\n",
        "cep\t\t     \t\t\t\t\t\t\t\t\t\t  |int     | cep         |\n",
        "  "
      ],
      "metadata": {
        "id": "LDPdcceBpgBa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dicionário do arquivo rating\n",
        "\n",
        "Fields\t                                                  | Type  \t  |    Description                              |\n",
        "----------------------------------------------------------|:---------:|:-------------------------------------------:|\n",
        "ind_user \t  \t\t\t\t\t\t\t\t\t\t  \t  |int     | Coluna do usuário |\n",
        "indice_filme\t\t\t\t\t\t\t\t\t\t\t\t\t\t  |int    | Coluna do filme              |\n",
        "avaliacao\t\t     \t\t\t\t\t\t\t\t\t\t  |int     | Avaliação (nota)              |\n",
        "data\t\t     \t\t\t\t\t\t\t\t\t\t  |timestamp     | data em timestamp               |\n"
      ],
      "metadata": {
        "id": "MqDU8SQ7p-O_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalação dos pacotes"
      ],
      "metadata": {
        "id": "pbGrHxYcsJK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas numpy scikit-learn keras torch torchvision torchaudio\n",
        "\n"
      ],
      "metadata": {
        "id": "L4sIIas-sDif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Documentação\n",
        "\n",
        "1. **Pandas** -> [Link](https://pandas.pydata.org/docs/)\n",
        "2. **Numpy** -> [Link](https://numpy.org/doc/)\n",
        "3. **Scikit Learn** -> [Link](https://scikit-learn.org/stable/)\n",
        "4. **Keras** -> [Link](https://keras.io/api/)\n",
        "5. **TensorFlow** -> [Link](https://www.tensorflow.org/api_docs/python/tf/keras)\n",
        "6. **PyTorch** -> [Link](https://pytorch.org/docs/stable/index.html)\n"
      ],
      "metadata": {
        "id": "8oALLv4OsLtG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Obtendo o dataset"
      ],
      "metadata": {
        "id": "gO-2UwZhXIfq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/batestin1/coding_the_future_dio_redes_neurais.git #clona o repositorio\n",
        "!mv coding_the_future_dio_redes_neurais/dataset /content/ #move apenas a pasta dataset para fora do diretorio\n",
        "!rm -rf coding_the_future_dio_redes_neurais #exclui o restante que nao nos interessa\n",
        "\n"
      ],
      "metadata": {
        "id": "35jUnruXXKyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalando as bibliotecas\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_xzqHGdzsPsR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np  # Biblioteca para operações numéricas e manipulação de arrays.\n",
        "import pandas as pd  # Biblioteca para análise e manipulação de dados.\n",
        "import os  # Biblioteca para interações com o sistema operacional, como manipulação de arquivos e diretórios.\n",
        "import torch  # Biblioteca principal do PyTorch para operações de tensor.\n",
        "import torch.nn as nn  # Submódulo do PyTorch para a construção de redes neurais.\n",
        "import torch.nn.parallel  # Submódulo do PyTorch para treinamento paralelo de redes neurais.\n",
        "import torch.optim as optim  # Submódulo do PyTorch para algoritmos de otimização.\n",
        "import torch.utils.data  # Submódulo do PyTorch para manipulação de conjuntos de dados.\n",
        "from torch.autograd import Variable  # Classe do PyTorch para autograd, que permite a diferenciação automática de operações em tensores.\n",
        "from keras.models import load_model  # Função para carregar modelos pré-treinados do Keras.\n",
        "from tensorflow.keras.models import load_model #para salvar modelos do keras\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9KXnKQabsQU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lendo os Dataset"
      ],
      "metadata": {
        "id": "p8XignQYXrjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importando os dados\n",
        "movies = pd.read_csv('/content/dataset/ae/movies.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
        "users = pd.read_csv('/content/dataset/ae/users.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
        "ratings = pd.read_csv('/content/dataset/ae/ratings.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')"
      ],
      "metadata": {
        "id": "G62zr7-eXuaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies.head(3)"
      ],
      "metadata": {
        "id": "wz2IwYcxYGIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies.columns = ['indice_filme', 'nome_filme', 'genero_filme']\n",
        "movies.head(3)"
      ],
      "metadata": {
        "id": "f7Y1VmhHqMIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users.head()"
      ],
      "metadata": {
        "id": "SI3XIk_zYIOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users.columns = ['indice_user', 'genero_user', 'idade_user', 'cod_profissao', 'cep']\n",
        "users.head()"
      ],
      "metadata": {
        "id": "K6oVLlqrq0bh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.head()"
      ],
      "metadata": {
        "id": "Rx0saFCIYJ7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.columns = ['ind_user', 'indice_filme', 'avaliacao', 'data']\n",
        "ratings.head()"
      ],
      "metadata": {
        "id": "W5D4lQ2IrX-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualizando_data = ratings.copy()\n",
        "visualizando_data['data'] = pd.to_datetime(visualizando_data['data'], unit='s')\n",
        "visualizando_data.head()"
      ],
      "metadata": {
        "id": "cM_qczTor-u_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparando os dados de treino e os dados de teste"
      ],
      "metadata": {
        "id": "HGRdTx-PYOxE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = pd.read_csv('/content/dataset/ae/train.csv') # Carrega o conjunto de dados de treinamento a partir de um arquivo CSV\n",
        "training_set = np.array(training_set, dtype = 'int') # Converte o conjunto de dados de treinamento em um array NumPy com o tipo de dados 'int'\n",
        "test_set = pd.read_csv('/content/dataset/ae/test.csv') # Carrega o conjunto de dados de teste a partir de um arquivo CSV\n",
        "test_set = np.array(test_set, dtype = 'int') # Converte o conjunto de dados de teste em um array NumPy com o tipo de dados 'int'"
      ],
      "metadata": {
        "id": "-e688oxuYLXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set.shape"
      ],
      "metadata": {
        "id": "lK-yQBVmrbHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set[0]"
      ],
      "metadata": {
        "id": "fjfgfikYNrLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_set.shape"
      ],
      "metadata": {
        "id": "S8DI0I5Greoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_set[0]"
      ],
      "metadata": {
        "id": "1wvztaS_OOQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set[:,0].max()"
      ],
      "metadata": {
        "id": "s15tR8w8P2Qt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_set[:,1].max()"
      ],
      "metadata": {
        "id": "cEAjla3VQVyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Quantidade de usuários e filmes\n",
        "nb_users = int(training_set[:,0].max()) # Encontra o maior ID de usuário no conjunto de treinamento\n",
        "nb_movies = int(training_set[:,1].max()) # Encontra o maior ID de filme  no conjunto de treinamento"
      ],
      "metadata": {
        "id": "tFk5fYa7YTIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_users"
      ],
      "metadata": {
        "id": "1BHH_B6_rZmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_movies"
      ],
      "metadata": {
        "id": "hPsY5RPUriYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para converter os dados em uma matriz com usuários nas linhas e filmes nas colunas\\\n",
        "#aqui vamos fazer uma lista para cada usuario que vai ter 6040 linhas e 3952 colunas\n",
        "def convert(data):\n",
        "    new_data = []\n",
        "    for id_users in range(1, nb_users + 1):  # Itera sobre cada ID de usuário\n",
        "        id_movies = data[:,1][data[:,0] == id_users]  # Obtém os IDs dos filmes avaliados pelo usuário atual\n",
        "        id_ratings = data[:,2][data[:,0] == id_users]  # Obtém as avaliações dos filmes feitas pelo usuário atual\n",
        "        ratings = np.zeros(nb_movies)  # Cria um vetor de zeros com o tamanho do número total de filmes\n",
        "        ratings[id_movies - 1] = id_ratings  # Atribui as avaliações aos índices correspondentes dos filmes\n",
        "        new_data.append(list(ratings))  # Adiciona o vetor de avaliações à nova lista de dados\n",
        "    return new_data  # Retorna a nova matriz de dados\n",
        "\n",
        "# Converte o conjunto de dados de treinamento usando a função definida\n",
        "training_set = convert(training_set)\n",
        "\n",
        "# Converte o conjunto de dados de teste usando a função definida\n",
        "test_set = convert(test_set)\n"
      ],
      "metadata": {
        "id": "l8y8b8fOYo4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(training_set)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "VFzYZaudVMSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(training_set)"
      ],
      "metadata": {
        "id": "WO-NVaLPsAxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_set)"
      ],
      "metadata": {
        "id": "oCmso_PCsBaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Essa padronizacao do mesmo tamanho do arquivo de treino e teste significa que apesar do usuario ter ou não avaliado o filme, ele vai estar no arquivo e nossa rede vai aprender com isso. caso nao tenha avaliado, preenchemos com 0"
      ],
      "metadata": {
        "id": "7lOJn-lX6ROo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Criando Tensors do Torch\n"
      ],
      "metadata": {
        "id": "_OeQidhuYrwS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Aqui vamos criar os tensores do toach. Matrizes multidimensionais de um unico tipo, em nosso caso, float"
      ],
      "metadata": {
        "id": "-kbBl9ho6kMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = torch.FloatTensor(training_set) # Converte o conjunto de dados de treinamento para um tensor de ponto flutuante do PyTorch\n",
        "test_set = torch.FloatTensor(test_set) # Converte o conjunto de dados de teste para um tensor de ponto flutuante do PyTorch"
      ],
      "metadata": {
        "id": "jH5mXUXsYu2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set"
      ],
      "metadata": {
        "id": "kQLpxoqP65fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Criando a arquitetura da AE"
      ],
      "metadata": {
        "id": "DwUaOi69Yyvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class redes_auto_enconder(nn.Module): # Vamos utilizar o conceito de herança para empilhar (stack) nossa rede de autoencoder\n",
        "    def __init__(self, ):\n",
        "        super(redes_auto_enconder, self).__init__()\n",
        "        self.fc1 = nn.Linear(nb_movies, 20) # Define a primeira camada totalmente valor total de filmes que definimos no 'nb_movies', e o 20 é o numero de caracteristicas que vc define para o autoencoders detectar.\n",
        "        self.fc2 = nn.Linear(20, 10) # Define a segunda camada totalmente conectada com 20 entradas (que sao os valores da saida anterior) e 10 saídas\n",
        "        self.fc3 = nn.Linear(10, 20) # Define a terceira camada totalmente conectada com 10 entradas e 20 saídas\n",
        "        self.fc4 = nn.Linear(20, nb_movies) # Define a quarta camada totalmente conectada com 20 entradas e 'nb_movies' saídas\n",
        "        self.activation = nn.Sigmoid()  # Define a função de ativação Sigmoid que será usada após cada camada totalmente conectada\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.activation(self.fc1(x)) # X é o vector de entrada. Ela ativia os neuronios da primeira camada. Aplica a primeira camada e a função de ativação Sigmoid\n",
        "        x = self.activation(self.fc2(x))  # Aplica a segunda camada e a função de ativação Sigmoid\n",
        "        x = self.activation(self.fc3(x))  # Aplica a terceira camada e a função de ativação Sigmoid\n",
        "        x = self.fc4(x) # Aplica a quarta camada (sem função de ativação)\n",
        "        return x #retorna o valor do vector\n",
        "\n",
        "\n",
        "rae = redes_auto_enconder() # Instancia a rede autoencoder\n",
        "\n",
        "\n",
        "criterion = nn.MSELoss() # metodo que será usado para metrificar o error. a metrica é MSE\n",
        "\n",
        "# Este otimizador vai ativar o Stochastic Gradient Descent para atualizar os pesos e reduzir o erro.\n",
        "optimizer = optim.RMSprop(rae.parameters(), # estamos utilizando o metodo parameters do torch que traz uma serie automatica de parametros do objeto.\n",
        "                          lr=0.01,          # é a taxa de aprendizado\n",
        "                          weight_decay=0.5) # Aqui é taxa de decaimento de peso\n"
      ],
      "metadata": {
        "id": "I5DxFIeMY0td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Treinando a AE"
      ],
      "metadata": {
        "id": "uFQqfmK6Y4UL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "nb_epoch = 8  # Define o número de épocas (iterações completas sobre o conjunto de dados) como 8, mas recomendo que em casa você use 800\n",
        "\n",
        "for epoch in range(1, nb_epoch + 1):  # Loop para cada época\n",
        "\n",
        "    train_loss = 0  # Variavel que armazena a taxa de perda, iniciando em 0\n",
        "    s = 0.0  # Vai contar o numero de usuario que avaliaram pelo menos 1 filme.\n",
        "\n",
        "    for id_user in range(nb_users):  # Loop sobre cada usuário\n",
        "\n",
        "        input = Variable(training_set[id_user]).unsqueeze(0)  # Cria uma variável a partir do conjunto de treinamento do usuário atual e adiciona uma dimensão, pq o pytorch nao aceita variavel de uma unica dimensao.\n",
        "\n",
        "        target = input.clone() #target é o valor real, e por isso recebe nossa entrada (input) clonada.\n",
        "\n",
        "        # este if só vai analisar usuarios que avaliaram o filme. Por isso o target.data é maior que 0 para pegar estes usuarios\n",
        "        if torch.sum(target.data > 0) > 0:  # Verifica se há alguma avaliação (dado > 0) para o usuário atual\n",
        "            output = rae(input)  # Passa o input através da rede autoencoder para obter o output\n",
        "            target.require_grad = False  # Desabilita o cálculo do gradiente para o target\n",
        "            output[target == 0] = 0  # Define as saídas correspondentes a zero no target também como zero no output\n",
        "            loss = criterion(output, target)  # Calcula a perda entre o output e o target usando a função de perda definida\n",
        "            # Calcula um fator de correção para a média, dividindo o número total de filmes pelo número de filmes avaliados pelo usuário\n",
        "            mean_corrector = nb_movies / float(torch.sum(target.data > 0) + 1e-10)\n",
        "            loss.backward()  # Realiza a retropropagação do erro para ajustar os pesos da rede\n",
        "            # Acumula a perda de treino corrigida pela média dos filmes avaliados\n",
        "            train_loss += np.sqrt(loss.data * mean_corrector)\n",
        "            s += 1.  # Incrementa o contador de usuários com dados válidos\n",
        "            optimizer.step()  # Atualiza os pesos da rede de acordo com o otimizador\n",
        "    # Imprime o número da época e a perda média de treino para a época atual\n",
        "    print('epoch: ' + str(epoch) + ' loss: ' + str(train_loss / s))\n"
      ],
      "metadata": {
        "id": "Clt7r9foY7y1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testando a Rede"
      ],
      "metadata": {
        "id": "SspaKiyXY_T1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss = 0  # Inicializa a variável de perda de teste\n",
        "s = 0.  # Inicializa a variável de contagem de usuários com dados válidos para o teste\n",
        "for id_user in range(nb_users):  # Loop sobre cada usuário\n",
        "    # Cria uma variável a partir do conjunto de treinamento do usuário atual e adiciona uma dimensão\n",
        "    input = Variable(training_set[id_user]).unsqueeze(0)\n",
        "    # Cria uma variável a partir do conjunto de teste do usuário atual e adiciona uma dimensão\n",
        "    target = Variable(test_set[id_user]).unsqueeze(0)\n",
        "    if torch.sum(target.data > 0) > 0:  # Verifica se há alguma avaliação (dado > 0) para o usuário atual no conjunto de teste\n",
        "        output = rae(input)  # Passa o input através da rede autoencoder para obter o output\n",
        "        target.require_grad = False  # Desabilita o cálculo do gradiente para o target\n",
        "        output[target == 0] = 0  # Define as saídas correspondentes a zero no target também como zero no output\n",
        "        loss = criterion(output, target)  # Calcula a perda entre o output e o target usando a função de perda definida\n",
        "        mean_corrector = nb_movies / float(torch.sum(target.data > 0)) # Calcula um fator de correção para a média, dividindo o número total de filmes pelo número de filmes avaliados pelo usuário\n",
        "        loss.backward() #esse parametro vai dizer em que direcao os pesos vao ser atualizados (se diminui ou aumenta)\n",
        "        test_loss += np.sqrt(loss.data * mean_corrector) # Acumula a perda de teste corrigida pela média dos filmes avaliados\n",
        "        s += 1.  # Incrementa o contador de usuários com dados válidos\n",
        "\n",
        "# Imprime a perda média de teste para todos os usuários\n",
        "print('Loss de teste: ' + str(test_loss / s))\n"
      ],
      "metadata": {
        "id": "6x3t-T3hZFPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Salvando o modelo"
      ],
      "metadata": {
        "id": "lBZ0WfOuZGSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folder = 'ae/'\n",
        "\n",
        "# Verifica se o diretório existe e, se não existir, cria o diretório\n",
        "if not os.path.exists(folder):\n",
        "    os.makedirs(folder)\n",
        "\n",
        "\n",
        "# Salva o modelo no diretório especificado\n",
        "torch.save(rae.state_dict(), os.path.join(folder, 'modelo_autoencoder.pth'))"
      ],
      "metadata": {
        "id": "gCWcMAD6ZOTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importando os modelos"
      ],
      "metadata": {
        "id": "A4U0kkRcazAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carrega o estado do modelo a partir do arquivo salvo no diretório especificado\n",
        "# Antes de carregar o modelo, você precisa instanciar uma nova rede_autoencoder\n",
        "model = redes_auto_enconder()\n",
        "model.eval()\n",
        "# Carrega os pesos salvos do modelo\n",
        "model.load_state_dict(torch.load(os.path.join(folder, 'modelo_autoencoder.pth')))\n"
      ],
      "metadata": {
        "id": "49s5dkEhazvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "ZtAC6kaxlQIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss = 0\n",
        "s = 0.0\n",
        "\n",
        "for id_user in range(nb_users):\n",
        "    input = Variable(test_set[id_user]).unsqueeze(0)\n",
        "    target = Variable(test_set[id_user]).unsqueeze(0)\n",
        "\n",
        "    if torch.sum(target.data > 0) > 0:\n",
        "        output = rae(input)\n",
        "        target.require_grad = False\n",
        "        output[target == 0] = 0\n",
        "        loss = criterion(output, target)\n",
        "        mean_corrector = nb_movies / float(torch.sum(target.data > 0) + 1e-10)\n",
        "        test_loss += np.sqrt(loss.data * mean_corrector)\n",
        "        s += 1.0\n",
        "\n",
        "print('Test loss: ' + str(test_loss / s))"
      ],
      "metadata": {
        "id": "oaXz7-uEjmoJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}