{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Desafio Kaggle"
      ],
      "metadata": {
        "id": "JNq9v0qeDqge"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Descriçao\n",
        "\n",
        "---\n",
        "1. O objetivo deste notebook é simular um desafio kaggle.\n",
        "2. Utilizaremos o conjunto de dados direto do github, a qual iremos baixar e usar.\n",
        "\n",
        "3. O problema consiste em prever agrupar e criar sistemas de recomendações a partir de avaliações de filmes\n",
        "---"
      ],
      "metadata": {
        "id": "dkI1byzSDxoI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dicionário\n",
        "\n",
        "\n",
        "Fields\t                                                  | Type  \t  |    Description                              |\n",
        "----------------------------------------------------------|:---------:|:-------------------------------------------:|\n",
        "Date \t  \t\t\t\t\t\t\t\t\t\t  \t  |string     | Data da alteração |\n",
        "Open\t\t\t\t\t\t\t\t\t\t\t\t\t\t  |float    | preço da abertura                        |\n",
        "High\t\t     \t\t\t\t\t\t\t\t\t\t  |float     | preço mais alto no dia\t               |\n",
        "Low | float | preco mais baixo no dia\n",
        "Close | float | preco de fechamento\n",
        "Volume | float | Volume total do dia\n",
        "  "
      ],
      "metadata": {
        "id": "Snlor2ijEDz9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalação dos pacotes"
      ],
      "metadata": {
        "id": "QYUkt8XUEIwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalação das bibliotecas necessárias\n",
        "!pip install numpy pandas torch\n"
      ],
      "metadata": {
        "id": "T14lqffXDuMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Documentação\n",
        "\n",
        "1. **Pandas** -> [Link](https://pandas.pydata.org/docs/)\n",
        "2. **Numpy** -> [Link](https://numpy.org/doc/)\n",
        "3. **Scikit Learn** -> [Link](https://scikit-learn.org/stable/)\n",
        "4. **Keras** -> [Link](https://keras.io/api/)\n",
        "5. **TensorFlow** -> [Link](https://www.tensorflow.org/api_docs/python/tf/keras)\n",
        "6. **PyTorch** -> [Link](https://pytorch.org/docs/stable/index.html)\n",
        "7. **Kaggle** -> [Link](https://www.kaggle.com/c/predict-movie-ratings/overview)"
      ],
      "metadata": {
        "id": "HYXelGL1EV0i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Obtendo o dataset"
      ],
      "metadata": {
        "id": "offlG2cEEn6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/batestin1/coding_the_future_dio_redes_neurais.git #clona o repositorio\n",
        "!mv coding_the_future_dio_redes_neurais/dataset /content/ #move apenas a pasta dataset para fora do diretorio\n",
        "!rm -rf coding_the_future_dio_redes_neurais #exclui o restante que nao nos interessa\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DdGdH4yEqtN",
        "outputId": "f1a4e152-74c3-400c-e67d-aed8effd400c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'coding_the_future_dio_redes_neurais'...\n",
            "remote: Enumerating objects: 10986, done.\u001b[K\n",
            "remote: Counting objects: 100% (54/54), done.\u001b[K\n",
            "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
            "remote: Total 10986 (delta 24), reused 38 (delta 13), pack-reused 10932\u001b[K\n",
            "Receiving objects: 100% (10986/10986), 191.19 MiB | 27.33 MiB/s, done.\n",
            "Resolving deltas: 100% (47/47), done.\n",
            "Updating files: 100% (11021/11021), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalando as bibliotecas\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GvjjjInlEtmp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01lpu215DfKB"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Obtendo dados"
      ],
      "metadata": {
        "id": "OGJzh31-FDWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#obtendo dados\n",
        "training_set = pd.read_csv('/content/dataset/kaggle/train_v2.csv')\n",
        "training_set = np.array(training_set, dtype = 'int')\n",
        "test_set = pd.read_csv('/content/dataset/kaggle/test_v2.csv')\n",
        "test_set = np.array(test_set, dtype = 'int')\n"
      ],
      "metadata": {
        "id": "-YQfP52UFCDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparando o notebook"
      ],
      "metadata": {
        "id": "keqW7aD9FrXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#obtendo maiores valores\n",
        "nb_users = int(max(max(training_set[:,0]), max(test_set[:,0])))\n",
        "nb_movies = int(max(max(training_set[:,1]), max(test_set[:,1])))\n",
        "\n",
        "#convertendo dados para formato de avaliações\n",
        "def convert(data):\n",
        "    new_data = []\n",
        "    for id_users in range(1, nb_users + 1):\n",
        "        id_movies = data[:,1][data[:,0] == id_users]\n",
        "        id_ratings = data[:,2][data[:,0] == id_users]\n",
        "        ratings = np.zeros(nb_movies)\n",
        "        ratings[id_movies - 1] = id_ratings\n",
        "        new_data.append(list(ratings))\n",
        "    return new_data\n",
        "training_set = convert(training_set)\n",
        "test_set = convert(test_set)\n",
        "\n",
        "#criando tensors do torch\n",
        "training_set = torch.FloatTensor(training_set)\n",
        "test_set = torch.FloatTensor(test_set)\n",
        "\n",
        "#criando classe de treino\n",
        "class SAE(nn.Module):\n",
        "    def __init__(self, ):\n",
        "        super(SAE, self).__init__()\n",
        "        self.fc1 = nn.Linear(nb_movies, 20)\n",
        "        self.fc2 = nn.Linear(20, 10)\n",
        "        self.fc3 = nn.Linear(10, 20)\n",
        "        self.fc4 = nn.Linear(20, nb_movies)\n",
        "        self.activation = nn.Sigmoid()\n",
        "    def forward(self, x):\n",
        "        x = self.activation(self.fc1(x))\n",
        "        x = self.activation(self.fc2(x))\n",
        "        x = self.activation(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "#Instânciando a classe\n",
        "sae = SAE()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.RMSprop(sae.parameters(), lr = 1e-2, weight_decay = 0.5)\n",
        "\n",
        "#Treinando\n",
        "nb_epoch = 200\n",
        "for epoch in range(1, nb_epoch + 1):\n",
        "    train_loss = 0\n",
        "    s = 0.\n",
        "    for id_user in range(nb_users):\n",
        "        input = Variable(training_set[id_user]).unsqueeze(0)\n",
        "        target = input.clone()\n",
        "        if torch.sum(target.data > 0) > 0:\n",
        "            output = sae(input)\n",
        "            target.require_grad = False\n",
        "            output[target == 0] = 0\n",
        "            loss = criterion(output, target)\n",
        "            mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
        "            loss.backward()\n",
        "            train_loss += np.sqrt(loss.data*mean_corrector)\n",
        "            s += 1.\n",
        "            optimizer.step()\n",
        "    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))\n",
        "\n"
      ],
      "metadata": {
        "id": "uXqpImtdFlyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testando\n"
      ],
      "metadata": {
        "id": "oaQsk3E2FwPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#testando\n",
        "test_loss = 0\n",
        "s = 0.\n",
        "for id_user in range(nb_users):\n",
        "    input = Variable(training_set[id_user]).unsqueeze(0)\n",
        "    target = Variable(test_set[id_user]).unsqueeze(0)\n",
        "    if torch.sum(target.data > 0) > 0:\n",
        "        output = sae(input)\n",
        "        target.require_grad = False\n",
        "        output[target == 0] = 0\n",
        "        loss = criterion(output, target)\n",
        "        mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
        "        test_loss += np.sqrt(loss.data*mean_corrector)\n",
        "        s += 1.\n",
        "print('Loss de teste: '+str(test_loss/s))"
      ],
      "metadata": {
        "id": "FUcIe4UcFxHu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}