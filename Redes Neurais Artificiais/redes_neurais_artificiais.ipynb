{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "sX_UanypdKgV",
        "h7cpFlL1dTZY",
        "5o03GRfD9FaM"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Redes Neurais Artificiais"
      ],
      "metadata": {
        "id": "_iHaEpaLShxD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Descriçao\n",
        "\n",
        "---\n",
        "1. O objetivo deste notebook é a construir sua primeira rede neural.\n",
        "2. Utilizaremos o conjunto de dados proposto no [gist](https://gist.githubusercontent.com/batestin1/e09def5cbd3732e345029f5c88155182/raw/a14ff6964c3fbeeca3b7f17ec32102f0ade14828/gistfile1.txt)\n",
        "\n",
        "3. O problema consiste em prever e classificar a perda de clientes que a empresa esta sofrendo. Investigar os motivos para isso.\n",
        "---"
      ],
      "metadata": {
        "id": "8sWWwgp_UC5N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dicionário\n",
        "\n",
        "\n",
        "Fields\t                                                  | Type  \t  |    Description                              |\n",
        "----------------------------------------------------------|:---------:|:-------------------------------------------:|\n",
        "RowNumber \t  \t\t\t\t\t\t\t\t\t\t  \t  |int     | número da linha |\n",
        "CustomerId\t\t\t\t\t\t\t\t\t\t\t\t\t\t  |int    | número do id                         |\n",
        "Surname\t\t     \t\t\t\t\t\t\t\t\t\t  |string     | sobrenome da pessoa \t               |\n",
        "CreditScore | int | avaliação de crédito (igual serasa)\n",
        "Geography | string | Região em que existe\n",
        "Gender | string | Genero\n",
        "Age | int | idade do cliente\n",
        " Tenure  | int | Quantidade de Posses (bens) que ele(a) possuí\n",
        "  Balance  | float64 | Balanço da conta\n",
        "    NumOfProducts  | int | Número de produtos comprados\n",
        "      HasCrCard  | int | Se ele possui ou não cartão de crédito (0 para sim, 1 para não)\n",
        "        IsActiveMember  | int | É um cliente ativo (0 para sim, 1 para não)\n",
        "                EstimatedSalary  | float | Salário base (anualmente)\n",
        "                Exited  | int | Se o cliente saiu ou não da empresa (0 para sim, 1 para não)\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "zPvkUsRkUcOi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalação dos pacotes"
      ],
      "metadata": {
        "id": "Pnpl071jbWl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas numpy scikit-learn keras"
      ],
      "metadata": {
        "id": "ymVg-V9QbYWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Documentação\n",
        "\n",
        "1. ** Pandas ** -> [Link](https://pandas.pydata.org/docs/)\n",
        "2. ** Numpy ** -> [Link](https://numpy.org/doc/)\n",
        "4. ** Scikit Learn ** -> [Link](https://scikit-learn.org/stable/)\n",
        "5. ** Keras ** -> [Link](https://keras.io/api/)\n",
        "6. ** Tensor Flow ** -> [Tensor Flow](https://www.tensorflow.org/api_docs/python/tf/keras)\n",
        "7. ** JobLib ** -> [JobLib](https://joblib.readthedocs.io/en/stable/)\n"
      ],
      "metadata": {
        "id": "IgtQLZFGbjK4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importando as Bibliotecas"
      ],
      "metadata": {
        "id": "2Yp4zCoUbs7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os #para manipular pastas e diretórios\n",
        "import pandas as pd #para manipulacao de dados\n",
        "import numpy as np # para criação de matrizes\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler # para pre processamento de ml\n",
        "from sklearn.compose import make_column_transformer #para efetivar a mudanca de oneHotEncoder\n",
        "from sklearn.model_selection import train_test_split #para separar treino e teste\n",
        "from sklearn.metrics import confusion_matrix #para avaliar nosso modelo\n",
        "\n",
        "import tensorflow as tf # para construir um perceptron (não que vamos usar, mas apenas para entender)\n",
        "from keras.models import Sequential # O sequential é para inicializar a rede neural\n",
        "from keras.layers import Dense # DENSE cria as camadas da redes neural (camadas densas sao aquelas que camadas interconectadas)\n",
        "\n",
        "from keras.models import load_model #para carregar modelos\n",
        "\n"
      ],
      "metadata": {
        "id": "jxzio59AbuU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Obtendo o dataset"
      ],
      "metadata": {
        "id": "mgq5fiEMcbn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://gist.githubusercontent.com/batestin1/e09def5cbd3732e345029f5c88155182/raw/a14ff6964c3fbeeca3b7f17ec32102f0ade14828/gistfile1.txt')\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "7d3UXTNoSj73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conhecendo o dataset"
      ],
      "metadata": {
        "id": "Re0kgl5GcjaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "HDHby9b3Tnjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Pre Processamento dos dados"
      ],
      "metadata": {
        "id": "sphW4J79ct9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#separando os dados em X e y\n",
        "\n",
        "\n",
        "X = df.iloc[:, 3:13].values # pega da terceira coluna (a partir da 0) até a 13 (na verdade, ele vai pegar a 12)\n",
        "y = df.iloc[:, 13].values #pega somente a 13\n"
      ],
      "metadata": {
        "id": "h8mWoeBJUiJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "S__EaZr7iAcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "xw0AmXH7iCeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[:, 2]"
      ],
      "metadata": {
        "id": "qHU27J7j1CzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformação de Dados Categóricos\n",
        "labelencoder_X_1 = LabelEncoder()\n",
        "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1]) #transforma a coluna paises!\n",
        "\n",
        "labelencoder_X_2 = LabelEncoder()\n",
        "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2]) #transforma o genero\n",
        "\n",
        "ohe= make_column_transformer((OneHotEncoder(categories='auto', sparse = False), [1]), remainder=\"passthrough\") #realizo o processo de One Hot Encode para gerar colunas 0 e 1 dos paises e dos generos\n",
        "\n",
        "X=ohe.fit_transform(X)\n",
        "\n",
        "X = X[:,1:]"
      ],
      "metadata": {
        "id": "ys6u3nQNc_bA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dividir dados em treino e teste"
      ],
      "metadata": {
        "id": "sX_UanypdKgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "MRL0TSXedLu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### padronizando os dados"
      ],
      "metadata": {
        "id": "h7cpFlL1dTZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sc = StandardScaler() #metodo que vai padronizar a escala dos dados, entre 0 e 1\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "metadata": {
        "id": "HtW-ADr9dOJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Perceptron (opcional)"
      ],
      "metadata": {
        "id": "5o03GRfD9FaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#criando uma copia dos dados de treino e teste\n",
        "X_train_p = X_train\n",
        "X_Test_p = X_test\n",
        "y_train_p = y_train\n",
        "y_test_p = y_test\n",
        "\n",
        "#nosso perceptron\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid', input_shape=([11]))\n",
        "])\n",
        "\n",
        "# Compilando o modelo\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Treinando o modelo\n",
        "model.fit(X_train_p, y_train_p, epochs=10, verbose=1)\n",
        "\n",
        "# Avaliando o modelo\n",
        "loss, accuracy = model.evaluate(X_Test_p, y_test_p)\n",
        "print(f'Acurácia do modelo: {round(accuracy, 2) * 100}%')"
      ],
      "metadata": {
        "id": "jbhcGLOm9HNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Criando nossa RNA"
      ],
      "metadata": {
        "id": "CIt6mCoddY7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = Sequential()\n",
        "#adicionando Camadas\n",
        "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = X_train.shape[1])) #units é qut de neuronios que ela vai ter. kernel_initializer é qual metodo ele vai inicializar a rede.\n",
        "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu')) #A funcão de ativação é  especialmente em camadas intermediárias. Essa função retorna 0 se a entrada for menor ou igual a 0 e retorna a entrada diretamente se ela for maior que 0.\n",
        "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid')) # a função de ativação é suave. Ela transforma a saída linear de um neurônio em um valor entre 0 e 1, interpretável como a probabilidade de pertencer à classe positiva\n",
        "#Compilando\n",
        "#o compile é a função que vai realizar o processo de inteligencia da nossa rede neural\n",
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy']) #'adam' é um otimizador que realiza a funcao gradient descent (metodo que encontra melhores pesos dentro da rede) para encontrar. Loss é a função de perda que vai calculando a perda entre sinapses e ajustando de acordo com o backpropagation\n",
        "#Treinando\n",
        "classifier.fit(X_train, y_train, batch_size = 10, epochs = 100) #metodo que treina, passamos aqui o tamanho de batchs a serem processados de acordo com os epochs."
      ],
      "metadata": {
        "id": "011P2pZ7dWBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Prevendo dados de teste"
      ],
      "metadata": {
        "id": "eH011IvLderk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = classifier.predict(X_test) #realizando a previsão (ela vem em termos percentuais)\n",
        "y_pred = (y_pred > 0.5)\n",
        "\n",
        "\n",
        "# visualizando em porcentagem\n",
        "z_pred = np.array([f\"{value[0] * 100:.2f}%\" for value in y_pred])\n",
        "print(z_pred)"
      ],
      "metadata": {
        "id": "y2MyyLc2djNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Avaliando o modelo"
      ],
      "metadata": {
        "id": "e_Qem_dzdmbl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm"
      ],
      "metadata": {
        "id": "WUfe2JZSdoBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = pd.DataFrame(cm)\n",
        "cm"
      ],
      "metadata": {
        "id": "dw7nutwESSWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculando o que significa elas (usando formula simples)\n",
        "\n",
        "tamanho_do_teste = y_test.shape[0]\n",
        "verdadeiros_positivos = cm.values[0][0]\n",
        "falsos_positivos = cm.values[1][1]\n",
        "\n",
        "acuracia = (verdadeiros_positivos + falsos_positivos) / tamanho_do_teste\n",
        "\n",
        "print(f\"Acuracia da RNA foi de {round(acuracia, 2) * 100}%\")"
      ],
      "metadata": {
        "id": "skwggaB1TToz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Salvando o modelo"
      ],
      "metadata": {
        "id": "diaaPnLcd8AU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folder = 'rna/'\n",
        "\n",
        "# Verifica se o diretório existe e, se não existir, cria o diretório\n",
        "if not os.path.exists(folder):\n",
        "    os.makedirs(folder)\n",
        "\n",
        "# Salva o modelo no diretório especificado\n",
        "classifier.save(os.path.join(folder, 'rede_neural_one.h5'))"
      ],
      "metadata": {
        "id": "V9F61yJ7d-hm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importando o modelo para uso"
      ],
      "metadata": {
        "id": "dAoh--T2fa1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(os.path.join(folder, 'rede_neural_one.h5'))\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = (y_pred > 0.7)"
      ],
      "metadata": {
        "id": "zBw0q3Owd_bz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm"
      ],
      "metadata": {
        "id": "peP5Nd3tg2aL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}