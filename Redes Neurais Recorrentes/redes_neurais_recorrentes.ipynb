{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "K7WovfBKkl8d"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Redes Neurais Recorrentes"
      ],
      "metadata": {
        "id": "A-h53Z50hj0-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Descriçao\n",
        "\n",
        "---\n",
        "1. O objetivo deste notebook é construir uma Rede Neural Recorrente.\n",
        "2. Utilizaremos o conjunto de dados proposto no [gist treino](https://gist.githubusercontent.com/batestin1/b8f7c0a26c9669013ba451c18e381d75/raw/e355693a14880cd8dbe2bee26a52dafdc9aaabec/gistfile1.txt) e [gist test](https://gist.githubusercontent.com/batestin1/f94107b82cc271c203c1d5843b8dded3/raw/f5e653d96b45bb19773230b5090c78f0695f8919/gistfile1.txt)\n",
        "\n",
        "3. O problema consiste em prever as ações temporais do preço da Google na bolsa de valores\n",
        "---"
      ],
      "metadata": {
        "id": "PJB3tpd7hok1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dicionário\n",
        "\n",
        "\n",
        "Fields\t                                                  | Type  \t  |    Description                              |\n",
        "----------------------------------------------------------|:---------:|:-------------------------------------------:|\n",
        "Date \t  \t\t\t\t\t\t\t\t\t\t  \t  |string     | Data da alteração |\n",
        "Open\t\t\t\t\t\t\t\t\t\t\t\t\t\t  |float    | preço da abertura                        |\n",
        "High\t\t     \t\t\t\t\t\t\t\t\t\t  |float     | preço mais alto no dia\t               |\n",
        "Low | float | preco mais baixo no dia\n",
        "Close | float | preco de fechamento\n",
        "Volume | float | Volume total do dia\n",
        "  "
      ],
      "metadata": {
        "id": "YVo2gtjgiLoY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalação dos pacotes"
      ],
      "metadata": {
        "id": "6Lt6i3j5i_xV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas numpy scikit-learn keras matplotlib"
      ],
      "metadata": {
        "id": "zf-NZ28kjAms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Documentação\n",
        "\n",
        "1. ** Pandas ** -> [Link](https://pandas.pydata.org/docs/)\n",
        "2. ** Numpy ** -> [Link](https://numpy.org/doc/)\n",
        "4. ** Scikit Learn ** -> [Link](https://scikit-learn.org/stable/)\n",
        "5. ** Keras ** -> [Link](https://keras.io/api/)\n",
        "6. ** Tensor Flow ** -> [Tensor Flow](https://www.tensorflow.org/api_docs/python/tf/keras)\n",
        "\n"
      ],
      "metadata": {
        "id": "4YpmKO3YjDFB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalando as bibliotecas\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "d11LZE2kjFJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np #para manipulacao e criacao de matrizes\n",
        "import matplotlib.pyplot as plt #para visualizacao dos dados\n",
        "import pandas as pd #para manipulacao de dados\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler # para pre processamento de ml\n",
        "\n",
        "from keras.models import Sequential # para iniciar nossa rede neural\n",
        "from keras.layers import Dense #para criar os neuronios\n",
        "from keras.layers import LSTM #para corrigir nosso vanishing gradient, a solucao LSTM\n",
        "from keras.layers import Dropout #para reduzir o overfitting\n",
        "\n",
        "import os # para criacao e manipulacao de pastas\n",
        "from keras.models import load_model #para salvar modelos do keras\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable\n"
      ],
      "metadata": {
        "id": "dL4RVruphx5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Obtendo o dataset"
      ],
      "metadata": {
        "id": "Va76O8i9jutR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://gist.githubusercontent.com/batestin1/b8f7c0a26c9669013ba451c18e381d75/raw/e355693a14880cd8dbe2bee26a52dafdc9aaabec/gistfile1.txt')\n"
      ],
      "metadata": {
        "id": "8aQCfXkviNkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Conhecendo o dataset"
      ],
      "metadata": {
        "id": "xnAlaoobjyF-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "FdujZpjZiVNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#vendo o periodo\n",
        "ano_inicial = df['Date'].min()\n",
        "ano_final = df['Date'].max()\n",
        "\n",
        "print(ano_inicial[5:], ano_final[4:])"
      ],
      "metadata": {
        "id": "VEw66dSbf52l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pré Processamento"
      ],
      "metadata": {
        "id": "jUZsYfzsj1kH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separando os dados de treino\n",
        "training_set = df.iloc[:, 1:2].values #aqui estou pegando uma array da coluna 'open' o valor de abertura do mercado\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IS08AeXSidWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num = 115\n",
        "print(f\"comparando o training_set: {training_set[num][0]} X coluna open: {df['Open'][num]}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Jx3wEtetjkUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc = MinMaxScaler(feature_range = (0, 1)) #padronizando os dados de treino. O feature_range é um alcance entre 0 e 1\n",
        "training_set_scaled = sc.fit_transform(training_set) #aplicando o metodo\n",
        "training_set_scaled"
      ],
      "metadata": {
        "id": "xk23pQHSjg4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set_scaled.shape"
      ],
      "metadata": {
        "id": "tAhsymaZuQ-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Estruturas de dados com 60 intervalos\n",
        "X_train = []\n",
        "y_train = []\n",
        "for i in range(60, len(training_set_scaled)): #este 60 indica o inicio de nosso range, o modelo vai olhar 60 dias para trás para prever o próximo da frente.\n",
        "    X_train.append(training_set_scaled[i-60:i, 0]) #o indice i-60:i, 0], indica que esta pegando todos do i, 60 intervalos para trás, jogando na nossa lista vazia X_train\n",
        "    y_train.append(training_set_scaled[i, 0]) #jogando na nossa lista vazia y_train\n",
        "X_train, y_train = np.array(X_train), np.array(y_train) #criando uma matriz para X e para y"
      ],
      "metadata": {
        "id": "UvbynrOrkMTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "RTB1tRwVpQJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ajustar Formato\n",
        "#transformando em uma matriz em tres dimensao,\n",
        "\n",
        "parametros = (\n",
        "    X_train.shape[0], #batch size, o numero de linhas de nossa matriz\n",
        "    X_train.shape[1], #o numero de passos a serem realizados (tmb o numero de colunas)\n",
        "    1 #nosso indicador, nosso indicador vai ser o Open\n",
        ")\n",
        "\n",
        "\n",
        "X_train = np.reshape(X_train, (parametros))\n",
        "X_train.shape"
      ],
      "metadata": {
        "id": "NL28x3kUkS-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "xKTkll-br6hV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Construindo nossa RNR"
      ],
      "metadata": {
        "id": "g2cwlr8ikTgd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Inicializando a RNA\n",
        "rnr = Sequential()"
      ],
      "metadata": {
        "id": "b1SUGVvwtsNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Criando as camadas\n",
        "rnr.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1))) #a primeira camada é LSTM, o return_sequence é do LSTM e entende que ele precisa retorna em forma de sequencia. o input_shape só precisa de duas dimensoes, pq a quantidade de observacoes é automatico\n",
        "rnr.add(Dropout(0.2)) #para reduzir o overfitting, o parametro 0,2 indica o numero de neuronios que ele desativa apos a leitura da primeira.\n",
        "rnr.add(LSTM(units = 50, return_sequences = True))\n",
        "rnr.add(Dropout(0.2))\n",
        "rnr.add(LSTM(units = 50, return_sequences = True))\n",
        "rnr.add(Dropout(0.2))\n",
        "rnr.add(LSTM(units = 50))\n",
        "rnr.add(Dropout(0.2))\n",
        "rnr.add(Dense(units = 1)) #para conectar todos os neuronios. A camada de saida."
      ],
      "metadata": {
        "id": "wGA5sD15kVHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compilando\n",
        "\n",
        "rnr.compile(optimizer = 'adam', loss='mean_squared_error') # como se trata de um problema de regressao, a metrica q funcao de erro tem que usar é o mean_squared_error\n"
      ],
      "metadata": {
        "id": "6Pp8fjiBkcWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#treinando o modelo\n",
        "\n",
        "rnr.fit(X_train, y_train, epochs = 100, batch_size = 32)"
      ],
      "metadata": {
        "id": "VbG__Qjbxn5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testando"
      ],
      "metadata": {
        "id": "od500yVLz5Az"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dados_de_teste = pd.read_csv('https://gist.githubusercontent.com/batestin1/f94107b82cc271c203c1d5843b8dded3/raw/f5e653d96b45bb19773230b5090c78f0695f8919/gistfile1.txt')\n",
        "\n",
        "dados_de_teste"
      ],
      "metadata": {
        "id": "vlHyouXiz3TL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "abertura_real = dados_de_teste.iloc[:,1:2].values #pegando os dados da coluna Open\n",
        "abertura_real"
      ],
      "metadata": {
        "id": "_SHQ8Ux60N6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_total = pd.concat((df['Open'], dados_de_teste['Open']), axis = 0) #concatenando os dois valores, o teste e o treino do original\n",
        "dataset_total"
      ],
      "metadata": {
        "id": "-NzOTtUV0kJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = dataset_total[len(dataset_total) - len(dados_de_teste) - 60:].values #pegando o 60 dias antes do ultimo dia de janeiro de 2017 até o ultimo dia de 2016"
      ],
      "metadata": {
        "id": "9bZgvubn1dwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs.shape"
      ],
      "metadata": {
        "id": "KksRERwS32TV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#organizando ela para o formato de matriz que precisamos para testar\n",
        "\n",
        "inputs = inputs.reshape(-1,1)\n",
        "inputs.shape"
      ],
      "metadata": {
        "id": "zkba-Vei3rKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#padronizacao dos numeros\n",
        "inputs = sc.transform(inputs)\n",
        "inputs"
      ],
      "metadata": {
        "id": "enxKQh744A6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#utilizando a mesma preparacao que fizemos para o treino, agora para o teste.\n",
        "X_test = []\n",
        "for i in range(60, inputs.shape[0]):\n",
        "    X_test.append(inputs[i-60:i, 0])\n",
        "X_test = np.array(X_test)\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))"
      ],
      "metadata": {
        "id": "vF4NSFDo4QAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#obtendo a metrica da previsao\n",
        "\n",
        "print(f\"previsao oficial: {rnr.predict(X_test)}\")\n",
        "print(f\"previsao revertida: {sc.inverse_transform(rnr.predict(X_test))}\")\n",
        "\n",
        "variavel_final = sc.inverse_transform(rnr.predict(X_test))\n"
      ],
      "metadata": {
        "id": "VlfSSVlJ4rQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "abertura_real[9][0]"
      ],
      "metadata": {
        "id": "Jw7Re9kh6umf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"abertura oficial: {abertura_real[7][0]}\")\n",
        "print(f\"previsao obtida {round(sc.inverse_transform(rnr.predict(X_test))[7][0])}\")\n",
        "\n",
        "#variavel_final = sc.inverse_transform(rnr.predict(X_test))"
      ],
      "metadata": {
        "id": "grvW_mBx6ob-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dados_de_teste[dados_de_teste['Open'] == 807.14]"
      ],
      "metadata": {
        "id": "tYnGaYGw7X93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculando a previsao do modelo\n",
        "valor_final = round(sc.inverse_transform(rnr.predict(X_test))[7][0],2)\n",
        "valor_inicial = abertura_real[7][0]\n",
        "diferenca_percentual = ((valor_inicial - valor_final ) / valor_inicial) * 100\n",
        "print(f\"Diferença percentual: {diferenca_percentual:.2f}%\")"
      ],
      "metadata": {
        "id": "0fFwEJza7wI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Salvando o modelo"
      ],
      "metadata": {
        "id": "K7WovfBKkl8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folder = 'rnr/'\n",
        "\n",
        "# Verifica se o diretório existe e, se não existir, cria o diretório\n",
        "if not os.path.exists(folder):\n",
        "    os.makedirs(folder)\n",
        "\n",
        "# Salva o modelo no diretório especificado\n",
        "rnr.save(os.path.join(folder, 'rede_neural_recorrente.h5'))"
      ],
      "metadata": {
        "id": "Joe_KgcJknEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importando o modelo"
      ],
      "metadata": {
        "id": "ndHrOSQNkvjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(os.path.join(folder, 'rede_neural_recorrente.h5'))"
      ],
      "metadata": {
        "id": "xkWkm6LDlZMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizando o Resultado"
      ],
      "metadata": {
        "id": "fYvzeQatlerr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(abertura_real, color = 'red', label = 'Dados Reais de Ações do Google')\n",
        "plt.plot(variavel_final, color = 'blue', label = 'Dados Previstos de Ações do Google')\n",
        "plt.title('Previsão de Preços de Ações')\n",
        "plt.xlabel('Tempo')\n",
        "plt.ylabel('Preços de Ações do Google')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EDB_zKaulg2y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}